\section{Теоретическая часть}
\subsection{Случайные события и случайная величина}

{\it Статистическое испытание} - это наблюдение, производимое при неизменном комплексе контролируемых условий.

Всякий исход испытания называется {\it случайным событием}. 

В нашем опыте случайным событием является попадание зернышка в какую-либо из ячеек.

Случайные события принято описывать количественно с помощью случайных величин. Например, номер ячейки \textbf{n}, в которую попало зернышко, время падения в ячейку или пройденный до ячейки путь - это случайные величины, относящиеся к рассматриваемому случайному событию.

\subsubsection{Свойство статистической устойчивости. Относительная частота и вероятность события}

Ключевое понятие вероятности случайного события опирается на свойство \textit{статистической устойчивости}, которое поясним на примере.

Пусть зёрнышко брошено на доску Гальтона \textit{N} раз. Обозначим $N_k$ число испытаний, в которых зерно попало в ячейку с заданным номером \textit{k}(или же один раз брошено \textit{N} одинаковых зёрен, тогда $N_k$ - число зёрен в \textit{k}-й ячейке). Отношение $P^*(k,N) = \frac{N_k}{N}$ называется \textit{относительной частотой} события, заключающегося в попадании зерна в ячейку с номером \textit{k} в серии из \textit{N} испытаний. По-другому можно сказать, что это относительная частота того, что случайный номер ячейки \textit{n} примет значение \textit{k}.

Относительная частота - случайная величина. Но если провести $N$ одинаковых испытаний, то окажется, что чем больше $N$, тем меньше относительная частота зависит от $N$. Это свойство называется статистической устойчивостью относительной частоты появления случайного события. Именно статистическая устойчивость позволяет построить для случайных явлений и величин теорию, предсказывающую результаты многократно воспроизводимых(при одинаковых условиях) испытаний. Статистическая устойчивость - частный случай появления основного статистического закона, который называется законом больших чисел.

На математическом языке тот факт, что с увеличением $N$ относительная частота становится всё менее случайной, записывается в виде
\begin{align}
	\lim\limits_{N\to\infty}P^\ast(k,N) = \lim\limits_{N\to\infty}\frac{N_k}{N} = P(k)
\end{align}

Детерминорованную величину $P(k)$ называют вероятностью случайного события. В данном случае событие состоит в попадании зерна в $k$-ю ячейку, в то же время можно сказать, что $P(k)$ есть вероятность того, что случайная величина $n$ равна $k$.

\subsubsection{Дискретные и непрерывные случайные величины}
Случайною величину $X$, которая может принимать ограниченное или счётное число значений $\{x_1, x_2,\dots, x_n,\dots\}$, называют \textit{дискретной}. В нашем случае дискретной величиной является номер ячейки.
Величины, принимающие непрерывный ряд значений(например, время падения зерна в ячейку), называют \textit{непрерывными} случайными величинами.

\subsection{Закон распределения случайной величины}
\subsubsection{Закон распределения дискретной случайной величины}
Все свойства дискретной случайной величины определяются вероятностью возможных значений:
\begin{align*}
	P(k_1) = p_1, P(k_2) = p_2, \dots, P(k_n) = p_n, \dots
\end{align*}
 
Если набор значений невелик, то составляют таблицу, первая строка которой включает все значения случйной величины, а вторая - их вероятности. При этом говорят, что задан \textit{закон распределения} случайной дискретной величины. Тот же закон можно представить графически, откладывая по оси абсцисс значения, которые принимает случайная величина, а на оси ординат - их вероятности. 
 
\subsubsection{Интегральная и дифференциальная функции распределения}
Запись распределения случайных величин в виде таблицы неудобна в аналитических расчётах. Удобнее использовать \textit{функцию распределения}. По определению \textit{интегральная функция распределения}
\begin{align} \label{integr_func_raspr}
	F(x) = P(X < x)
\end{align}

равна вероятности того, что случайна величина $X$ принимает значение, меньшее наперёд заданного $x$. Интегральная функция распределения обладает следующими свойствами:
\begin{enumerate}
	\item $F(x)$ - неубывающая функция $x$, определённая на всей оси $x\in(-\infty,\infty)$ и принимающая значения в интервале $[0, 1]$.
	\item {Наименьшее значение функции $F(x)$ достигается при $x = -\infty$, а наибольшее - при $x = \infty$.
	\begin{align}
		F(-\infty)=0, \qquad F(\infty) = 1.
	\end{align}
	}
\end{enumerate}

Применительно к дискретной случайной величине $F(x)$ представляет собой кусочно-постоянную функцию, терпящую скачки в точках разрешённых значений $x_k$ случайной величины $X$:
\begin{align} \label{raspr_diskr}
	F(x) = \sum_{k}{p_k \chi (x - x_k).}
\end{align}
В записи (\ref{raspr_diskr}) использована $\chi$ - единичная функция 
\begin{align}
	\chi(x) = \left \{ 
	\begin{aligned}
		0, \qquad x \leq 0 \\
		1, \qquad x > 0
	\end{aligned} \right.
\end{align}

так что величина скачка равна вероятности $p_k$.

Интегральная функция распределения непрерывной случайной величины является гладкой монотонно возрастающей.

Наряду с интегральной функцией распределения часто используют и \textit{дифференциальную функцию распределения}, или \textit{плотность вероятностей}, по определению равную 
\begin{align} \label{opr_dif_func_raspr}
	W(x) = \frac{dF}{dx}
\end{align}

 Если интервал $\Delta x$ достаточно мал, то из (\ref{opr_dif_func_raspr}) и (\ref{integr_func_raspr})  следует, что величина $W(x)\Delta x$ будет приближённо равна вероятности попадания случайной величины $X$ в интервал значений $\Delta x$. Поэтому с помощью плотности вероятностей можно найти вероятность попадания случайной величины $X$ в любой наперёд заданный интервал $[a, b)$:
 \begin{align}
 	P(a \leq X < b) = \int_{a}^{b}{W(x)dx}
 \end{align}
 
 В частности, отсуда следует явное выражение для интегральной функции распределения через плотность вероятностей 
 \begin{align} \label{inter_func_raspr_cherez_plot_ver}
 	F(x) = P(X < x) = \int_{-\infty}^{x}{W(x)dx}
 \end{align}
 
 Перечислим общие свойства плотности вероятностей:
 \begin{enumerate}
 	\item Из (\ref{opr_dif_func_raspr}) и (\ref{integr_func_raspr}) видно, что плотность вероятностей имеет размерность, обратную размерности случайной величины $X$.
 	\item 
 	{ 
 		Плотность вероятностей неотрицательна:
 		
 		\begin{align}
 			W(x) \geq 0.
 		\end{align}
 	}
 	\item 
 	{
 		Для плотность вероятностей выполнено \textit{условие нормировки}, которое получим, устремив в \eqref{inter_func_raspr_cherez_plot_ver} $x$ к бесконечности:
 		
 		\begin{align} \label{usl_normirovki}
 			\int_{-\infty}^{\infty}{W(z)dz} = 1
 		\end{align}
 	}
 \end{enumerate}
 
 
 \subsubsection{Среднее значение и дисперсия}
 Пусть дискретная случайная величина $X$ в $N$ независимых испытаниях принимает значения $x_1,x_2, \dots, x_N$. Тогда среднее значение (его будем обозначать чертой сверху) равно
 \begin{align} \label{sr_znach}
 	\overline X = \frac{1}{N} \sum_{i=1}^{N}X_i.
 \end{align}
 
 Здесь $X_i$ - исход $i-$го испытания. Вычислим предел среднего арифметического при безграничном увеличении $N$. Для этого перегруппируем слагаемые считая, что значения $x_k$ выпадают $N_k$ раз. Тогда
 \begin{align}
 	\overline X = \sum_{k}{x_k \frac{N_k}{N}}.
 \end{align}
 
 При большом $N$ каждая дробь под знаком суммы даёт вероятность $p_k$, в итоге 
 \begin{align} \tag{12a} \label{x_sr_sum}
 	\overline X = \sum_{k}{x_k p_k} 
 \end{align}
 
 Равенство \eqref{x_sr_sum} является определением среднего значения дискретной случайной величины. Его ещё называют \textit{математическое ожидание} и обозначают $E_x$.
 Математическое ожидание (среднее значение) непрерывной случайной величины вычисляется с помощью плотности вероятностей:
  \begin{align*} \tag{12b} \label{x_sr_int}
 	\overline X = \int_{ -\infty }^{ \infty } (x W(x) dx)
 \end{align*}
 
 Ещё более информативной, чем математическое ожидание является \textit{дисперсия} случайной величины $D_x$, по определению равная:
 \begin{align} 
 	D_x = \overline{(X - \overline{X})^2}
 \end{align}

Из определения среднего значения следует, что дисперсия дискретной случайной величины вычисляется по формуле: